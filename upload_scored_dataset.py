import os
from datasets import load_dataset
from huggingface_hub import HfApi

# --- Configuration ---
# 1. Set your Hugging Face username.
#    This will be used to create the new repository under your account.
#    Example: HF_USERNAME = "my-awesome-username"
HF_USERNAME = "Thermostatic"  # <<<--- IMPORTANT: REPLACE WITH YOUR HF USERNAME

# 2. Define the input and output repository names.
#    The script will take the original repo name and add "-Scored".
ORIGINAL_REPO_BASE_NAME = "OPUS-100-EN-ES"
SCORED_REPO_NAME = f"{ORIGINAL_REPO_BASE_NAME}-Scored"
FULL_REPO_ID = f"{HF_USERNAME}/{SCORED_REPO_NAME}"

# 3. The name of the local CSV file generated by the scoring script.
LOCAL_CSV_FILENAME = "opus_en_es_wmt22_scored.csv"


def upload_to_hub():
    """
    Loads a scored CSV file, converts it to a Hugging Face Dataset,
    and uploads it to the Hub in Parquet format.
    """
    # --- 1. Pre-flight Checks ---
    print("--- Starting Upload Process ---")
    if HF_USERNAME == "YOUR_HF_USERNAME_HERE":
        print("❌ Error: Please update the 'HF_USERNAME' variable in the script with your Hugging Face username.")
        return

    if not os.path.exists(LOCAL_CSV_FILENAME):
        print(f"❌ Error: The file '{LOCAL_CSV_FILENAME}' was not found.")
        print("Please ensure you have run the scoring script first to generate the CSV.")
        return
    
    print(f"✅ Found local file: '{LOCAL_CSV_FILENAME}'")

    # --- 2. Load the CSV data into a Hugging Face Dataset ---
    # The `load_dataset` function with 'csv' will automatically create
    # a `DatasetDict` with a 'train' split, which is exactly what we need.
    print(f"Loading data from '{LOCAL_CSV_FILENAME}' into a Dataset object...")
    try:
        scored_dataset_dict = load_dataset("csv", data_files=LOCAL_CSV_FILENAME)
        # We need the Dataset object itself, not the dictionary containing it.
        scored_dataset = scored_dataset_dict['train']
    except Exception as e:
        print(f"❌ Error loading CSV file: {e}")
        return

    print("✅ Dataset loaded successfully. Features:")
    print(scored_dataset.features)
    print(f"Number of rows: {len(scored_dataset)}")
    
    # --- 3. Push the dataset to the Hub ---
    # The `push_to_hub` method handles the conversion to Parquet format automatically.
    # It will also create the repository if it doesn't exist.
    print(f"\n🚀 Uploading dataset to the Hugging Face Hub...")
    print(f"   Target repository: {FULL_REPO_ID}")

    try:
        scored_dataset.push_to_hub(
            repo_id=FULL_REPO_ID,
            commit_message=f"Upload scored {ORIGINAL_REPO_BASE_NAME} dataset",
            private=False  # Set to True if you want the repo to be private
        )
        print("\n--- Upload Complete! ---")
        print(f"✅ Successfully uploaded the dataset.")
        print(f"You can view your new dataset repository at:")
        print(f"   https://huggingface.co/datasets/{FULL_REPO_ID}")

    except Exception as e:
        print(f"\n❌ An error occurred during the upload process.")
        print(f"   Please ensure you are logged in to the Hugging Face CLI.")
        print(f"   You can log in by running: huggingface-cli login")
        print(f"   Original error: {e}")


if __name__ == "__main__":
    upload_to_hub()